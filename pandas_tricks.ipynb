{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas tricks & pitfalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mini_movie_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `rename` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the 'movie' column to 'title'.\n",
    "# you can rename multiple columns by adding more key:value pairs to the dictionary\n",
    "df.rename(columns={'movie':'title'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique studio names are there?\n",
    "print len(df.studio.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.studio.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values will not be sorted, you have to do it yourself\n",
    "print sorted(df.studio.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = df.groupby('actor')\n",
    "# this is a groupby object. do not be scared. it is your friend.\n",
    "actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the groupby object does not immediately reveal any information about itself.\n",
    "But it is easy to make it reveal its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first row in each group\n",
    "# (I keep putting .head() just so the printed dataframe won't fill up your whole screen. It's not needed)\n",
    "actors.first().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the last row of each group\n",
    "actors.last().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean of all rows for each group.\n",
    "# columns which you can't take the mean of will automatically be dropped.\n",
    "actors.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a group by name:\n",
    "actors.get_group('Gary Oldman').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling size() on a groupby object will return the number of rows each group contains.\n",
    "# here, how many roles each actor has\n",
    "actors.size().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg() can take a list of functions. \n",
    "# It makes a new column and applies them to each group in a groupby\n",
    "actors['domestic_gross','worldwide_gross'].agg(['mean','count','std','min','max']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASIDE: which female actors appear most often in the dataset?\n",
    "top_actresses = df[df.male==0].groupby('actor').size().sort_values(ascending=False).head()\n",
    "top_actresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# often we want to select all rows where a column contains any value in a list\n",
    "# eg, select all rows where df.actor is in our list of actors\n",
    "actor_list = ['Susan Sarandon','Julia Roberts']\n",
    "# This won't work:\n",
    "# df[df.actor in actor_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead, use pandas.DataFrame.isin:\n",
    "df[df.actor.isin(actor_list)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd.to_numeric()\n",
    "\n",
    "Converts a series, array, or dataframe to a numeric datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example DataFrame of numbers-as-strings\n",
    "num_example = pd.DataFrame(data=zip(list('2049204795'),list('6185700963')), columns=['a','b'])\n",
    "num_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you add columns a and b, they're just concatenated together because they're strings!\n",
    "num_example.a + num_example.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pd.to_numeric across the whole dataframe to convert everything to numeric values\n",
    "num_numeric = num_example.apply(pd.to_numeric)\n",
    "num_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now adding the columns actually gives you the sum\n",
    "num_numeric.a + num_numeric.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this example illustrates 2 things:\n",
    "# 1) grouping based on a conditional statement (is an even number)\n",
    "# 2) iterating through groups in a groupby\n",
    "for name, group in num_numeric.groupby(num_numeric.a%2==0):\n",
    "    print name, '\\n', group\n",
    "    print '* * *'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall what the actor info dataframe looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the data type (dtype) of the bday column?\n",
    "df.bday.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also print an element of the column to look at it\n",
    "df.bday[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also check the type of the first element\n",
    "type(df.bday[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the columns of date-time strings to pandas Timestamp objects (similar to to_numeric)\n",
    "# we don't use .apply here because we only want to change these 2 specified columns\n",
    "for datetime_col in ['bday','release_date']:\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bday.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.bday[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instant conversion to day/month/year with \n",
    "### `pd.Series.dt.<day/month/year/second/etc>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'years', df.bday.dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work.\n",
    "# df[df.bday > 1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead you could compare to a Timestamp or other datetime object\n",
    "df[df.bday > pd.to_datetime('1-1-1995')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, use the .dt syntax:\n",
    "df[df.bday.dt.year > 1995].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall!\n",
    "# when you want to select using multiple conditions, watch out for this pandas pitfall\n",
    "# (this doesn't work:)\n",
    "# df[2000 > df.bday.dt.year > 1995].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall!\n",
    "# Instead, use the bitwise and (&) operator. However...\n",
    "# (this doesn't work either):\n",
    "# df[2000 > df.bday.dt.year & df.bday.dt.year > 1995].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the '`&`' operator has really high precedence in order of operations, be sure to enclose each condition in *parentheses*.\n",
    "\n",
    "Eg: `2000 > df.bday.dt.year & df.bday.dt.year > 1995` is evaluated the same as \n",
    "\n",
    "`2000 > (df.bday.dt.year & df.bday.dt.year) > 1995`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select birthdays between 1995 and 2000, non-inclusive\n",
    "df[(2000 > df.bday.dt.year) & (df.bday.dt.year > 1995)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of .dt.month\n",
    "# Note: you rarely need to add columns like this!! You can use .dt directly for a groupby or for a selection\n",
    "df2 = df.copy()\n",
    "df2['release_month'] = df2.release_date.dt.month\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean = df.groupby(df.release_date.dt.month).mean()\n",
    "monthly_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean[['domestic_gross','worldwide_gross']].plot.bar(title='Mean monthly gross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't need to make a new column for a one-off.\n",
    "(monthly_mean.domestic_gross / monthly_mean.worldwide_gross).plot.bar(\n",
    "    title='Mean Domestic/Worldwide Gross Ratio by month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But that's gross, we don't want month numbers on the x axis, but the month names instead\n",
    "\n",
    "`calendar` library to the rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "# we have the option of full name of month, or abbreviated name\n",
    "print calendar.month_name[1:4]\n",
    "print calendar.month_abbr[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map over the the index of using calendar's month names\n",
    "monthly_mean.index = monthly_mean.index.map(lambda x: calendar.month_abbr[x])\n",
    "monthly_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have month abbreviations as x labels when we plot\n",
    "(monthly_mean.domestic_gross / monthly_mean.worldwide_gross).plot.bar(\n",
    "    title='Mean Domestic/Worldwide Gross Ratio by month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `resample` method\n",
    "\n",
    "A convenient way to bin timeseries data\n",
    "\n",
    "**Warning:** resample only works with a Timestamp-indexed dataframe. You can always set your index to your datetime column of interest `df.set_index('datetime_column')` to make this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at movies of a given actor, by year\n",
    "actor_df = df[df.actor=='Samuel L. Jackson'].drop('male', axis=1)\n",
    "actor_df.sort_values('release_date').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize what the data looks like now: it's irregular by year\n",
    "actor_df.plot('release_date','production_budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean of all the numerical columns\n",
    "actor_df.set_index('release_date').resample('AS', how='mean').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note that by default, missing bins get replaced with a NaN row. This is can be useful if you want to set a default value to the missing bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but fill all NaNs with 0\n",
    "actor_df.set_index('release_date').resample('AS', how='mean').fillna(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want 5-year bins instead, we can plug in a 5 to the resample \"rule\": '5AS'\n",
    "actor_df.set_index('release_date').resample('5AS', how='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resample resolutions available [(via SO answer)](http://stackoverflow.com/a/17001474):\n",
    "\n",
    "    B       business day frequency\n",
    "    C       custom business day frequency (experimental)\n",
    "    D       calendar day frequency\n",
    "    W       weekly frequency\n",
    "    M       month end frequency\n",
    "    BM      business month end frequency\n",
    "    CBM     custom business month end frequency\n",
    "    MS      month start frequency\n",
    "    BMS     business month start frequency\n",
    "    CBMS    custom business month start frequency\n",
    "    Q       quarter end frequency\n",
    "    BQ      business quarter endfrequency\n",
    "    QS      quarter start frequency\n",
    "    BQS     business quarter start frequency\n",
    "    A       year end frequency\n",
    "    BA      business year end frequency\n",
    "    AS      year start frequency\n",
    "    BAS     business year start frequency\n",
    "    BH      business hour frequency\n",
    "    H       hourly frequency\n",
    "    T       minutely frequency\n",
    "    S       secondly frequency\n",
    "    L       milliseonds\n",
    "    U       microseconds\n",
    "    N       nanoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say we want the mean, and also the count.\n",
    "# we can pass a list of methods to the `how`\n",
    "yr_bins = actor_df.set_index('release_date').resample('5AS', how=['mean','count','sem'])\n",
    "yr_bins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can get very fancy and pass a dict of dicts\n",
    "# the first key references the DataFrame's original column name\n",
    "# the second key defines the name of a new column.\n",
    "yr_bins = actor_df.set_index('release_date').resample('5AS', how={\n",
    "        'production_budget':{'avg':'mean', 'ct':'count', 'stdEm':'sem'},\n",
    "        'domestic_gross':{'low':'min', 'high':'max'},\n",
    "        'worldwide_gross':{'total':'sum'}})\n",
    "yr_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special note: try not to use method names as column names. It will make indexing more annoying.\n",
    "## For example, a column named 'mean' will cause a collision when you call `df.mean`\n",
    "## The `mean` method will have precedence.\n",
    "\n",
    "You'd only be able to access the column like: `df['mean']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PS: 'sem' is standard error of the mean\n",
    "# pd.Series.sem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_bins.production_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining the dot column name syntax is fine\n",
    "yr_bins.production_budget.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also index both levels of the column index by name, as strings\n",
    "yr_bins['production_budget','avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening a multi-level column index\n",
    "\n",
    "### Use a list comprehension to rewrite the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print yr_bins.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_bins_flat = yr_bins.copy()\n",
    "# use an underscore as a delimiter. But it's up to you.\n",
    "yr_bins_flat.columns = ['_'.join(col) for col in yr_bins.columns.values]\n",
    "\n",
    "yr_bins_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `pd.cut()`: bins numeric values -> categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some fake data\n",
    "no_movies = 10\n",
    "ratings_df = pd.DataFrame.from_dict({\n",
    "    'rating_no':pd.np.random.rand(no_movies), \n",
    "    'movie':df.title.sample(no_movies)})\n",
    "# fake gross based on fake rating\n",
    "ratings_df['gross'] = pd.np.round(ratings_df.rating_no*100000000, decimals=2)\n",
    "\n",
    "# save this unmodified version for later\n",
    "ratings_df_orig = ratings_df.copy()\n",
    "\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut numerical ratings into N bins\n",
    "\n",
    "# here's what the labels default to when you don't define your own labels\n",
    "ratings_df['rating_category_ugly'] = pd.cut(ratings_df.rating_no, bins=4)\n",
    "\n",
    "# you can substitute whatever labels you want\n",
    "ratings_df['rating_category'] = pd.cut(ratings_df.rating_no, bins=4, labels=['bad','mediocre','good','excellent'])\n",
    "\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `pd.cut` gives us an excellent way to groupby based on bins.\n",
    "# Eg, we can use the new categorical ratings to find the mean gross for each rating bin\n",
    "print 'mean gross for each rating bin'\n",
    "ratings_df.groupby('rating_category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if we didn't care about assigning labels like 'bad', 'mediocre', etc to the rating numbers,\n",
    "# pd.cut is still very useful if we want to groupby on binned numerical data\n",
    "\n",
    "# We can do this as a one-liner, using the copy of the original ratings_df before we added those extra columns.\n",
    "# Let's do 5 bins to switch it up.\n",
    "ratings_df_orig.groupby(pd.cut(ratings_df_orig.rating_no, bins=5)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just like with `resample`, empty bins have *NaN* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df_orig.groupby(pd.cut(ratings_df_orig.rating_no, bins=5), as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Taking advantage of seaborn's groupby support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 15\n",
    "# we only want one row per movie, we don't care about actors\n",
    "by_movie_df = df.groupby('title').first()\n",
    "by_movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the top N studios, by total production budget of all movies\n",
    "top_studio_names = by_movie_df.groupby('studio').sum().sort_values(\n",
    "    'production_budget', ascending=False).index[:n_top]\n",
    "\n",
    "top_studio_df = by_movie_df[by_movie_df.studio.isin(top_studio_names)]\n",
    "\n",
    "print top_studio_names\n",
    "top_studio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# make the size of the figure bigger (width,height)\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "# we pass the studio column to sns.violinplot\n",
    "sns.violinplot(top_studio_df.production_budget, groupby=top_studio_df.studio)\n",
    "plt.title('Production budget distributions for the top 10 studios');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
